import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from collections import Counter
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.cluster import KMeans
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from scipy import stats
import seaborn as sns

# 1. Average score & highest subject
def lab1():
    scores = np.random.randint(50, 100, (4, 4))  # 4x4 matrix
    avg = scores.mean(axis=0)
    best = np.argmax(avg)
    print("Average per subject:", avg)
    print("Highest Avg Subject Index:", best)

# 2. Average product price
def lab2():
    sales = np.random.randint(100, 1000, (3, 3))
    print("Average price:", sales.mean())

# 3. Average sale price of houses with >4 bedrooms
def lab3():
    data = np.array([[5, 2000, 300000], [3, 1800, 250000], [6, 2500, 450000]])
    filtered = data[data[:,0] > 4]
    print("Average price:", filtered[:,2].mean())

# 4. Total sales and % increase
def lab4():
    sales = np.array([2000, 2500, 3000, 4000])
    total = sales.sum()
    percent = ((sales[3] - sales[0]) / sales[0]) * 100
    print("Total:", total, "| Increase:", percent, "%")

# 5. Avg & % improvement in efficiency
def lab5():
    fuel = np.array([20, 25, 22, 30])
    print("Average:", fuel.mean())
    print("Improvement %:", ((fuel[3] - fuel[0]) / fuel[0]) * 100)

# 6. Total bill with discount & tax
def lab6():
    prices = [100, 200, 150]
    qty = [1, 2, 1]
    subtotal = sum(p*q for p,q in zip(prices, qty))
    total = subtotal * 0.9 * 1.05  # 10% discount, 5% tax
    print("Total Bill:", total)

# 7. Order Data Analysis
def lab7():
    df = pd.DataFrame({
        'CustomerID': [1, 2, 1, 3],
        'Date': pd.to_datetime(['2023-01-01','2023-01-03','2023-01-05','2023-01-07']),
        'Product': ['A','B','A','C'],
        'Qty': [2, 1, 4, 3]
    })
    print(df.groupby('CustomerID').size())
    print(df.groupby('Product')['Qty'].mean())
    print("Earliest:", df['Date'].min(), "| Latest:", df['Date'].max())

# 8. Top 5 products sold
def lab8():
    df = pd.DataFrame({'Product': ['A','B','A','C','B','A']})
    print(df['Product'].value_counts().head(5))

# 9. Property data analysis
def lab9():
    df = pd.DataFrame({
        'Location': ['X','Y','X'],
        'Bedrooms': [5, 3, 6],
        'Area': [2500, 1800, 3200],
        'Price': [400000, 250000, 500000]
    })
    print(df.groupby('Location')['Price'].mean())
    print((df['Bedrooms'] > 4).sum())
    print(df[df['Area'] == df['Area'].max()])

# 10. Monthly sales line/bar plot
def lab10():
    months = ['Jan','Feb','Mar','Apr']
    sales = [100, 150, 130, 170]
    plt.figure()
    plt.plot(months, sales, marker='o')
    plt.title("Line Plot")
    plt.show()
    plt.bar(months, sales)
    plt.title("Bar Plot")
    plt.show()

# 11. Line, scatter, bar plot for sales
def lab11():
    sales = [100, 120, 140, 160]
    plt.plot(sales)
    plt.title("Line Plot")
    plt.show()
    plt.scatter(range(len(sales)), sales)
    plt.title("Scatter Plot")
    plt.show()
    plt.bar(range(len(sales)), sales)
    plt.title("Bar Plot")
    plt.show()

# 12. Temp and Rainfall line and scatter plot
def lab12():
    temp = np.random.randint(20, 40, 12)
    rainfall = np.random.randint(50, 200, 12)
    plt.plot(temp)
    plt.title("Monthly Temperature")
    plt.show()
    plt.scatter(range(12), rainfall)
    plt.title("Monthly Rainfall")
    plt.show()

# 13. Frequency distribution from text
def lab13():
    with open("sample_text.txt") as f:
        words = f.read().lower().split()
        freq = Counter(words)
        print(freq)

# 14-16. Word/likes/age frequency
def lab14_16():
    data = pd.Series([21,22,21,24,23,21,22])
    print(data.value_counts())

# 17. Text frequency analysis from CSV
def lab17():
    df = pd.read_csv("data.csv")
    from nltk.corpus import stopwords
    import string
    stop_words = set(stopwords.words('english'))
    words = " ".join(df['feedback']).lower().translate(str.maketrans('', '', string.punctuation)).split()
    words = [w for w in words if w not in stop_words]
    freq = Counter(words)
    N = int(input("Top N frequent words: "))
    common = freq.most_common(N)
    print(common)
    pd.DataFrame(common).plot(kind='bar', x=0, y=1)
    plt.show()

# 18. Stats & plots on age and %fat
def lab18():
    df = pd.DataFrame({'Age': np.random.randint(20,60,18), '%Fat': np.random.rand(18)*40})
    print(df.mean(), df.median(), df.std())
    df.boxplot(column=['Age','%Fat'])
    plt.show()
    plt.scatter(df['Age'], df['%Fat'])
    plt.title("Scatter Plot")
    plt.show()
    stats.probplot(df['%Fat'], dist="norm", plot=plt)
    plt.show()

# 19. Confidence intervals for blood pressure
def lab19():
    new_drug = np.random.normal(10, 3, 50)
    placebo = np.random.normal(5, 2, 50)
    print(stats.t.interval(0.95, len(new_drug)-1, loc=np.mean(new_drug), scale=stats.sem(new_drug)))
    print(stats.t.interval(0.95, len(placebo)-1, loc=np.mean(placebo), scale=stats.sem(placebo)))

# 20. A/B test conversion comparison
def lab20():
    a = np.random.rand(50)
    b = np.random.rand(50)
    print("p-value:", stats.ttest_ind(a, b).pvalue)

# 21. Estimation from CSV
def lab21():
    df = pd.read_csv("rare_elements.csv")
    mean = df.mean()[0]
    conf_int = stats.t.interval(0.95, len(df)-1, loc=mean, scale=stats.sem(df.values.flatten()))
    print("CI:", conf_int)

# 22. Customer review CI
def lab22():
    df = pd.read_csv("customer_reviews.csv")
    print(stats.t.interval(0.95, len(df)-1, loc=df.mean()[0], scale=stats.sem(df.values.flatten())))

# 23. Hypothesis testing and visual
def lab23():
    group1 = np.random.normal(10, 3, 50)
    group2 = np.random.normal(6, 2, 50)
    sns.histplot(group1, color="blue", label="Drug", kde=True)
    sns.histplot(group2, color="red", label="Placebo", kde=True)
    plt.legend()
    plt.show()
    print("p-value:", stats.ttest_ind(group1, group2).pvalue)

# 24. KNN
def lab24():
    from sklearn.datasets import load_iris
    data = load_iris()
    knn = KNeighborsClassifier(n_neighbors=3)
    knn.fit(data.data, data.target)
    print("Predicted:", knn.predict([data.data[0]]))

# 25. Decision Tree - Iris
def lab25():
    from sklearn.datasets import load_iris
    data = load_iris()
    clf = DecisionTreeClassifier()
    clf.fit(data.data, data.target)
    print("Predicted:", clf.predict([data.data[1]]))

# 26. Linear regression housing
def lab26():
    X = np.array([[1500], [2000], [2500]])
    y = np.array([300000, 400000, 500000])
    model = LinearRegression().fit(X, y)
    print("Predicted:", model.predict([[2200]]))

# 27. Logistic Regression for churn
def lab27():
    X = np.array([[10, 1], [20, 0], [30, 1]])
    y = np.array([0, 1, 1])
    model = LogisticRegression().fit(X, y)
    print("Predicted:", model.predict([[25, 1]]))

# 28. K-Means customer clustering
def lab28():
    data = np.array([[1,2],[2,3],[10,12],[11,14]])
    km = KMeans(n_clusters=2).fit(data)
    print("Cluster:", km.predict([[2,3]]))

# 29. Evaluation metrics
def lab29():
    y_true = [0,1,1,0]
    y_pred = [0,1,0,0]
    print("Accuracy:", accuracy_score(y_true, y_pred))
    print("Precision:", precision_score(y_true, y_pred))
    print("Recall:", recall_score(y_true, y_pred))
    print("F1 Score:", f1_score(y_true, y_pred))

# 30. CART for car price
def lab30():
    from sklearn.tree import DecisionTreeRegressor
    X = np.array([[10, 5], [8, 6], [15, 4]])
    y = [300000, 280000, 400000]
    model = DecisionTreeRegressor().fit(X, y)
    print("Price:", model.predict([[12, 5]]))

# 31-34. K-Means clustering on various domains
def lab31_34():
    data = np.random.rand(100, 3)
    km = KMeans(n_clusters=4).fit(data)
    plt.scatter(data[:,0], data[:,1], c=km.labels_)
    plt.title("Customer Segmentation")
    plt.show()

# 35. Stock price variability
def lab35():
    df = pd.read_csv("stock_data.csv")
    print("Std Dev:", df['Close'].std())

# 36. Correlation: Study vs Score
def lab36():
    hours = np.random.randint(1, 10, 20)
    scores = hours * 10 + np.random.randint(-10, 10, 20)
    plt.scatter(hours, scores)
    plt.title("Study Time vs Score")
    plt.show()

# 37. Temp analysis by city
def lab37():
    cities = {'CityA': np.random.randint(20, 40, 365),
              'CityB': np.random.randint(10, 35, 365)}
    for city, temps in cities.items():
        print(city, "Mean:", temps.mean(), "Std:", temps.std())

# 38. Customer segmentation
def lab38():
    data = np.random.rand(50, 2)
    km = KMeans(n_clusters=3).fit(data)
    plt.scatter(data[:,0], data[:,1], c=km.labels_)
    plt.show()

# 39. Soccer players CSV analysis
def lab39():
    df = pd.read_csv("players.csv")
    print(df.sort_values('Goals', ascending=False).head(5))
    print(df.sort_values('Salary', ascending=False).head(5))
    avg_age = df['Age'].mean()
    print(df[df['Age'] > avg_age])
    df['Position'].value_counts().plot(kind='bar')
    plt.show()

# 40. Stock data variability
def lab40():
    df = pd.read_csv("stock_data.csv")
    print("Price Range:", df['Close'].max() - df['Close'].min())
